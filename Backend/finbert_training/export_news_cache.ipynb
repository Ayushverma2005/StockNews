{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c048dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_news_cache.py\n",
    "\"\"\"\n",
    "Export real news articles from SQLite news_cache database to CSV.\n",
    "Prepares data for pseudo-labeling and training.\n",
    "\"\"\"\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def export_news_cache_to_csv(\n",
    "    db_path: str,\n",
    "    export_path: str,\n",
    "    min_relevance: float = 0.0\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Export news articles from SQLite database to CSV format.\n",
    "    \n",
    "    Args:\n",
    "        db_path: Path to the SQLite database file\n",
    "        export_path: Path where CSV will be saved\n",
    "        min_relevance: Minimum relevance score filter (default: 0.0)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing exported news articles\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If database file doesn't exist\n",
    "        sqlite3.Error: If database query fails\n",
    "    \"\"\"\n",
    "    # Check if database exists\n",
    "    if not Path(db_path).exists():\n",
    "        raise FileNotFoundError(f\"Database not found: {db_path}\")\n",
    "    \n",
    "    print(f\"Connecting to database: {db_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Connect to SQLite database\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        \n",
    "        # SQL query to extract relevant news data\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            article_title,\n",
    "            article_content,\n",
    "            source_name,\n",
    "            published_date,\n",
    "            article_url,\n",
    "            relevance_score,\n",
    "            company_symbol\n",
    "        FROM news_cache\n",
    "        WHERE relevance_score >= ?\n",
    "        ORDER BY published_date DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"Executing query with min_relevance >= {min_relevance}...\")\n",
    "        \n",
    "        # Execute query and load into DataFrame\n",
    "        df = pd.read_sql_query(query, conn, params=(min_relevance,))\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        print(f\"✅ Loaded {len(df)} articles from database\")\n",
    "        \n",
    "        if df.empty:\n",
    "            print(\"⚠️  No articles found matching the criteria\")\n",
    "            return df\n",
    "        \n",
    "        # Combine title and content into single text field\n",
    "        print(\"Processing text fields...\")\n",
    "        df['text'] = df.apply(\n",
    "            lambda row: f\"{row['article_title']}. {row['article_content']}\"\n",
    "            if pd.notna(row['article_content']) and row['article_content'].strip()\n",
    "            else row['article_title'],\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Remove rows with empty text\n",
    "        initial_len = len(df)\n",
    "        df = df[df['text'].str.strip() != ''].copy()\n",
    "        \n",
    "        if len(df) < initial_len:\n",
    "            print(f\"⚠️  Removed {initial_len - len(df)} articles with empty text\")\n",
    "        \n",
    "        # Rename columns for clarity\n",
    "        df = df.rename(columns={\n",
    "            'source_name': 'source',\n",
    "            'article_url': 'url',\n",
    "            'company_symbol': 'symbol'\n",
    "        })\n",
    "        \n",
    "        # Select and reorder columns\n",
    "        df = df[[\n",
    "            'text',\n",
    "            'source',\n",
    "            'published_date',\n",
    "            'url',\n",
    "            'relevance_score',\n",
    "            'symbol'\n",
    "        ]]\n",
    "        \n",
    "        # Create export directory if it doesn't exist\n",
    "        export_dir = Path(export_path).parent\n",
    "        export_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save to CSV\n",
    "        df.to_csv(export_path, index=False)\n",
    "        \n",
    "        print(f\"\\n✅ Exported to: {export_path}\")\n",
    "        print(f\"   Total articles: {len(df)}\")\n",
    "        print(f\"   Date range: {df['published_date'].min()} to {df['published_date'].max()}\")\n",
    "        print(f\"   Avg relevance score: {df['relevance_score'].mean():.3f}\")\n",
    "        print(f\"\\nSource distribution:\")\n",
    "        print(df['source'].value_counts())\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"❌ Database error: {str(e)}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during export: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"CLI entrypoint for news cache export.\"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Export news articles from SQLite cache to CSV\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--db_path\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Path to the SQLite database file\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--export_path\",\n",
    "        type=str,\n",
    "        default=\"./data/news_export.csv\",\n",
    "        help=\"Output CSV file path (default: ./data/news_export.csv)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--min_relevance\",\n",
    "        type=float,\n",
    "        default=0.0,\n",
    "        help=\"Minimum relevance score filter (default: 0.0)\"\n",
    "    )\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"News Cache Export\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Database: {args.db_path}\")\n",
    "    print(f\"Export path: {args.export_path}\")\n",
    "    print(f\"Min relevance: {args.min_relevance}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Export news cache\n",
    "        df = export_news_cache_to_csv(\n",
    "            db_path=args.db_path,\n",
    "            export_path=args.export_path,\n",
    "            min_relevance=args.min_relevance\n",
    "        )\n",
    "        \n",
    "        print(\"\\n✅ Export complete!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Export failed: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        exit(1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
